{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d8d693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 165740 entries, 129400 to 260403\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count   Dtype         \n",
      "---  ------       --------------   -----         \n",
      " 0   timestamp    165740 non-null  datetime64[ns]\n",
      " 1   city         165740 non-null  object        \n",
      " 2   temperature  165730 non-null  float64       \n",
      " 3   humidity     165730 non-null  float64       \n",
      " 4   windSpeed    165687 non-null  float64       \n",
      " 5   demand_mwh   160895 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(4), object(1)\n",
      "memory usage: 8.9+ MB\n",
      "None\n",
      "                 timestamp       city  temperature  humidity  windSpeed  \\\n",
      "129400 2018-07-01 07:00:00         la        65.45      0.79       4.23   \n",
      "260405 2018-07-01 07:00:00    phoenix        86.82      0.16       4.30   \n",
      "162552 2018-07-01 07:00:00  san diego        61.71      0.80       3.53   \n",
      "179128 2018-07-01 07:00:00   san jose        67.78      0.60       6.36   \n",
      "309499 2018-07-01 07:00:00    seattle        59.32      0.86       4.81   \n",
      "\n",
      "        demand_mwh  \n",
      "129400      9353.0  \n",
      "260405      2764.0  \n",
      "162552      1737.0  \n",
      "179128     10653.0  \n",
      "309499       774.0  \n",
      "Saved merged dataset to Data/combined_electric_load.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "# --- 1. Paths & filenames ---\n",
    "DATA_DIR = r'Data/'\n",
    "WEATHER_FILES = [\n",
    "    'dallas.json','houston.json','la.json','nyc.json',\n",
    "    'san_diego.json','san_jose.json','san_antonio.json',\n",
    "    'phoenix.json','philadelphia.json','seattle.json'\n",
    "]\n",
    "DEMAND_FILES = {\n",
    "    'nyc': 'cleaned_subregion_data.csv',\n",
    "    'phoenix': 'cleaned_balance_data.csv',\n",
    "    'seattle': 'cleaned_balance_data.csv',\n",
    "    'houston': 'cleaned_texas_data.csv',\n",
    "    'san antonio': 'cleaned_texas_data.csv',\n",
    "    'dallas': 'cleaned_texas_data.csv'\n",
    "}\n",
    "\n",
    "# --- 2. Load & unify weather JSONs ---\n",
    "weather_dfs = []\n",
    "for fname in WEATHER_FILES:\n",
    "    city_key = os.path.splitext(fname)[0].replace('_', ' ').lower()\n",
    "    file_path = os.path.join(DATA_DIR, fname)\n",
    "    df = pd.read_json(file_path)\n",
    "    df['city'] = city_key\n",
    "    df['timestamp'] = pd.to_datetime(df['time'], unit='s')\n",
    "    df.drop(columns=['time'], inplace=True)\n",
    "    weather_dfs.append(df)\n",
    "weather_df = pd.concat(weather_dfs, ignore_index=True)\n",
    "\n",
    "# --- 3. Load & unify demand sources ---\n",
    "demand_dfs = []\n",
    "for city, fname in DEMAND_FILES.items():\n",
    "    path = os.path.join(DATA_DIR, fname)\n",
    "    df = pd.read_csv(path)\n",
    "    # parse timestamp column\n",
    "    if 'local_time' in df.columns:\n",
    "        df['timestamp'] = pd.to_datetime(df['local_time'])\n",
    "    elif 'date' in df.columns:\n",
    "        df['timestamp'] = pd.to_datetime(df['date'])\n",
    "    # select & rename demand\n",
    "    df = df.rename(columns={'demand': 'demand_mwh'})\n",
    "    # ensure city column exists\n",
    "    if 'city' not in df.columns:\n",
    "        # texas file: pivot wide to long\n",
    "        df = df.melt(\n",
    "            id_vars=['timestamp'],\n",
    "            value_vars=[c for c in df.columns if c not in ['timestamp','date']],\n",
    "            var_name='city', value_name='demand_mwh'\n",
    "        )\n",
    "        df['city'] = df['city'].str.lower()\n",
    "    else:\n",
    "        df['city'] = df['city'].str.lower()\n",
    "    demand_dfs.append(df[['timestamp','city','demand_mwh']])\n",
    "demand_df = pd.concat(demand_dfs, ignore_index=True)\n",
    "\n",
    "# --- 4. Merge weather & demand ---\n",
    "combined_df = pd.merge(\n",
    "    weather_df,\n",
    "    demand_df,\n",
    "    on=['timestamp','city'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# --- 5. Remove duplicates ---\n",
    "# If multiple records share the same timestamp & city, keep the first valid demand\n",
    "combined_df = combined_df.sort_values(['timestamp','city','demand_mwh'], na_position='first')\n",
    "combined_df = combined_df.drop_duplicates(subset=['timestamp','city'], keep='last')\n",
    "\n",
    "# --- 6. Final cleanup & save ---\n",
    "cols = ['timestamp','city','temperature','humidity','windSpeed','demand_mwh']\n",
    "avail = [c for c in cols if c in combined_df.columns]\n",
    "combined_df = combined_df[avail]\n",
    "\n",
    "# inspect\n",
    "print(combined_df.info())\n",
    "print(combined_df.head())\n",
    "\n",
    "# save\n",
    "combined_df.to_csv(\"combined_data.csv\", index=False)\n",
    "print(f\"Saved merged dataset to {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea049be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      "timestamp         0\n",
      "city              0\n",
      "temperature      10\n",
      "humidity         10\n",
      "windSpeed        53\n",
      "demand_mwh     4845\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# --- 6. Count missing values per feature ---\n",
    "missing_counts = combined_df.isna().sum()\n",
    "print(\"Missing values per column:\")\n",
    "print(missing_counts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
